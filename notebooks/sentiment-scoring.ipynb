{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "from db_utils import table_exists, read_query_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = read_query_as_df(\"SELECT * FROM stock_prices\") if table_exists(\"stock_prices\") else pd.DataFrame()\n",
    "sentiment_df = read_query_as_df(\"SELECT * FROM sentiment_scores\") if table_exists(\"sentiment_scores\") else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('date' in stock_df.columns and 'date' in sentiment_df.columns):\n",
    "    # Convert the 'date' columns to datetime.date objects\n",
    "    stock_df['date'] = pd.to_datetime(stock_df['date']).dt.date\n",
    "    sentiment_df['date'] = pd.to_datetime(sentiment_df['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>date</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock        date  polarity  subjectivity\n",
       "0  AAPL  2017-01-31  0.000000           0.0\n",
       "1  AAPL  2017-05-03  0.000000           0.0\n",
       "2  AAPL  2017-05-23  0.000000           0.3\n",
       "3  AAPL  2017-07-29  0.500000           1.0\n",
       "4  AAPL  2018-02-01  0.216667           0.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_agg = sentiment_df.groupby(['stock', 'date']).agg({\n",
    "    'polarity': 'mean',\n",
    "    'subjectivity': 'mean'\n",
    "}).reset_index()\n",
    "sentiment_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(stock_df, sentiment_agg, on=['stock', 'date'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['daily_return'] = merged_df.groupby('stock')['close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['sentiment_spike'] = merged_df['polarity'] > 0.5\n",
    "merged_df['neg_sentiment'] = merged_df['polarity'] < -0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['vol_spike'] = merged_df.groupby('stock')['volume'].transform(\n",
    "    lambda x: x > x.rolling(7).mean() * 1.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['day_of_week'] = pd.to_datetime(merged_df['date']).dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['sentiment_label'] = merged_df['polarity'].apply(lambda x: \"Positive\" if x > 0.05 else \"Negative\" if x < -0.05 else \"Neutral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spike(group):\n",
    "    # Exclude 'stock' column from being recalculated if it's included\n",
    "    group = group.copy()\n",
    "    \n",
    "    group['rolling_mean'] = group['polarity'].rolling(window=3, min_periods=2).mean()\n",
    "    group['rolling_std'] = group['polarity'].rolling(window=3, min_periods=2).std()\n",
    "    group['sentiment_spike'] = (abs(group['polarity'] - group['rolling_mean']) > 0.6 * group['rolling_std'])\n",
    "    return group\n",
    "\n",
    "# Apply the function to each ticker\n",
    "merged_df = merged_df.sort_values(['stock', 'date'])  # just in case\n",
    "grouped = [detect_spike(group) for _, group in merged_df.groupby('stock')]\n",
    "merged_df = pd.concat(grouped).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 count      mean       std       min       25%       50%  \\\n",
      "spike_direction                                                            \n",
      "Negative Spike     8.0 -0.023055  0.046901 -0.131170 -0.026810 -0.012431   \n",
      "None              20.0 -0.015030  0.043821 -0.085630 -0.050767 -0.014787   \n",
      "Positive Spike    15.0 -0.006973  0.045758 -0.095157 -0.030413 -0.006651   \n",
      "\n",
      "                      75%       max  \n",
      "spike_direction                      \n",
      "Negative Spike  -0.000887  0.020041  \n",
      "None             0.005887  0.070033  \n",
      "Positive Spike   0.012462  0.081984  \n"
     ]
    }
   ],
   "source": [
    "merged_df['spike_direction'] = merged_df.apply(\n",
    "    lambda row: 'Positive Spike' if row['sentiment_spike'] and row['polarity'] > 0 \n",
    "    else 'Negative Spike' if row['sentiment_spike'] and row['polarity'] < 0 \n",
    "    else 'None', axis=1\n",
    ")\n",
    "\n",
    "print(merged_df.groupby('spike_direction')['daily_return'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['rolling_sentiment'] = merged_df.groupby('stock')['polarity'].transform(lambda x: x.rolling(7).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_spike(row):\n",
    "    if row['sentiment_spike'] and row['vol_spike']:\n",
    "        return \"Both\"\n",
    "    elif row['sentiment_spike']:\n",
    "        return \"Sentiment\"\n",
    "    elif row['vol_spike']:\n",
    "        return \"Volume\"\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "merged_df['spike_type'] = merged_df.apply(label_spike, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>stock</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>sentiment_spike</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>vol_spike</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>rolling_mean</th>\n",
       "      <th>rolling_std</th>\n",
       "      <th>spike_direction</th>\n",
       "      <th>rolling_sentiment</th>\n",
       "      <th>spike_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>247.100006</td>\n",
       "      <td>248.860001</td>\n",
       "      <td>244.419998</td>\n",
       "      <td>244.929993</td>\n",
       "      <td>51326400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>237.300003</td>\n",
       "      <td>242.460007</td>\n",
       "      <td>237.059998</td>\n",
       "      <td>239.410004</td>\n",
       "      <td>41153600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.484821</td>\n",
       "      <td>-0.039660</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.111117</td>\n",
       "      <td>Positive Spike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>216.979996</td>\n",
       "      <td>221.750000</td>\n",
       "      <td>214.910004</td>\n",
       "      <td>220.139999</td>\n",
       "      <td>62547500</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.085630</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.079539</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>215.240005</td>\n",
       "      <td>218.759995</td>\n",
       "      <td>213.750000</td>\n",
       "      <td>214.220001</td>\n",
       "      <td>54385400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.008019</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.118952</td>\n",
       "      <td>Negative Spike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-20</td>\n",
       "      <td>214.100006</td>\n",
       "      <td>217.490005</td>\n",
       "      <td>212.220001</td>\n",
       "      <td>213.990005</td>\n",
       "      <td>48862900</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.266886</td>\n",
       "      <td>0.458613</td>\n",
       "      <td>-0.005296</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.098486</td>\n",
       "      <td>0.169162</td>\n",
       "      <td>Positive Spike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       close        high         low        open    volume stock  \\\n",
       "0  2025-02-24  247.100006  248.860001  244.419998  244.929993  51326400  AAPL   \n",
       "1  2025-02-27  237.300003  242.460007  237.059998  239.410004  41153600  AAPL   \n",
       "2  2025-03-12  216.979996  221.750000  214.910004  220.139999  62547500  AAPL   \n",
       "3  2025-03-19  215.240005  218.759995  213.750000  214.220001  54385400  AAPL   \n",
       "4  2025-03-20  214.100006  217.490005  212.220001  213.990005  48862900  AAPL   \n",
       "\n",
       "   polarity  subjectivity  daily_return  sentiment_spike  neg_sentiment  \\\n",
       "0  0.000000      0.000000           NaN            False          False   \n",
       "1  0.157143      0.484821     -0.039660             True          False   \n",
       "2  0.100000      0.400000     -0.085630            False          False   \n",
       "3 -0.071429      0.214286     -0.008019             True          False   \n",
       "4  0.266886      0.458613     -0.005296             True          False   \n",
       "\n",
       "   vol_spike day_of_week sentiment_label  rolling_mean  rolling_std  \\\n",
       "0      False      Monday         Neutral           NaN          NaN   \n",
       "1      False    Thursday        Positive      0.078571     0.111117   \n",
       "2      False   Wednesday        Positive      0.085714     0.079539   \n",
       "3      False   Wednesday        Negative      0.061905     0.118952   \n",
       "4      False    Thursday        Positive      0.098486     0.169162   \n",
       "\n",
       "  spike_direction  rolling_sentiment spike_type  \n",
       "0            None                NaN       None  \n",
       "1  Positive Spike                NaN  Sentiment  \n",
       "2            None                NaN       None  \n",
       "3  Negative Spike                NaN  Sentiment  \n",
       "4  Positive Spike                NaN  Sentiment  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"../data/candlethrob_dataset.csv\", index=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  s.stock,\n",
    "  DATE(s.date) AS date,\n",
    "  COUNT(s.stock) AS total_mentions,\n",
    "  ROUND(AVG(s.polarity), 3) AS avg_sentiment,\n",
    "  ROUND(AVG(s.subjectivity), 3) AS avg_subjectivity,\n",
    "  sp.open,\n",
    "  sp.close,\n",
    "  (sp.close - sp.open) AS price_change,\n",
    "  sp.volume,\n",
    "  COUNT(s.stock) * ROUND(AVG(s.polarity), 3) AS signal_strength\n",
    "FROM sentiment_scores s\n",
    "LEFT JOIN stock_prices sp\n",
    "  ON s.stock = sp.stock AND DATE(s.date) = DATE(sp.date)\n",
    "GROUP BY s.stock, DATE(s.date)\n",
    "ORDER BY date;\n",
    "\"\"\"\n",
    "\n",
    "df = read_query_as_df(query)\n",
    "df.to_csv(\"../data/candlethrob_analysis.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
