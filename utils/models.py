"""
SQLAlchemy models for CandleThrob financial data pipeline.

This module contains the database models for storing ticker data and macroeconomic data
using Oracle database with SQLAlchemy ORM. Supports bulk inserts and incremental loading.
"""
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import pandas as pd
import logging
from datetime import datetime
from datetime import date as date_type
from typing import Optional
from CandleThrob.utils.oracle_conn import OracleDB


logger = logging.getLogger(__name__)

class TickerData():
    """Model for storing ticker data (OHLCV) with bulk insert and incremental loading support."""
    
    __tablename__ = 'ticker_data'
    
    def create_table(self, cursor):
        """Create the table if it doesn't exist."""
        try:
            cursor.execute(f"""
                BEGIN
                    EXECUTE IMMEDIATE 'CREATE TABLE {self.__tablename__} (
                        id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                        ticker VARCHAR2(10) NOT NULL,
                        trade_date DATE NOT NULL,
                        open_price NUMBER(10,4) NOT NULL,
                        high_price NUMBER(10,4) NOT NULL,
                        low_price NUMBER(10,4) NOT NULL,
                        close_price NUMBER(10,4) NOT NULL,
                        volume NUMBER NOT NULL,
                        vwap NUMBER(10,4),
                        num_transactions NUMBER,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )';
                EXCEPTION
                    WHEN OTHERS THEN
                        IF SQLCODE != -955 THEN  -- Table already exists
                            RAISE;
                        END IF;
                END;
            """)
            logger.info("TickerData table created/verified successfully")
        except Exception as e:
            logger.error("Error creating TickerData table: %s", e)
            raise

    def data_exists(self, cursor, ticker: Optional[str] = None) -> bool:
        """Check if data exists in the table."""
        try:
            if ticker:
                cursor.execute(f"SELECT 1 FROM {self.__tablename__} WHERE ticker = :ticker", {"ticker": ticker})
                return cursor.fetchone() is not None
            else:
                cursor.execute(f"SELECT 1 FROM {self.__tablename__}")
                return cursor.fetchone() is not None
        except Exception as e:
            logger.error("Error checking data existence: %s", e)
            return False

    def get_last_date(self, cursor, ticker: Optional[str] = None) -> Optional[date_type]:
        """Get the last date for which data exists."""
        try:
            if ticker:
                cursor.execute(f"SELECT MAX(trade_date) FROM {self.__tablename__} WHERE ticker = :ticker", {"ticker": ticker})
            else:
                cursor.execute(f"SELECT MAX(trade_date) FROM {self.__tablename__}")
            result = cursor.fetchone()
            return result[0] if result else None
        except Exception as e:
            logger.error("Error getting last date: %s", e)
            return None

    def insert_data(self, conn, df: pd.DataFrame):
        """Insert data using bulk operations with incremental loading."""
        if df is None or df.empty:
            logger.warning("No data to insert")
            return
        
        try:
            df_clean = df.copy()
                            
            column_mapping = {
                'open': 'open_price',
                'high': 'high_price', 
                'low': 'low_price',
                'close': 'close_price',
                'transactions': 'num_transactions'
            }
            df_clean = df_clean.rename(columns=column_mapping)
            
            required_cols = ['ticker', 'trade_date', 'open_price', 'high_price', 'low_price', 'close_price', 'volume', "vwap", "num_transactions"]
            df_clean = df_clean[required_cols]

            
            # Bulk insert using pandas to_sql with SQLAlchemy
            current_data = df_clean.to_dict(orient='records')
            cols = df_clean.columns.tolist()
            placeholders = ', '.join([':' + col for col in cols])
            insert_statement = f"""
            INSERT INTO ticker_data ({', '.join(cols)})
            VALUES ({placeholders})
            """
            
            from sqlalchemy import text
            with conn.begin() as transaction:
                transaction.execute(text(insert_statement), current_data)

            logger.info("Successfully inserted %d ticker records", len(df_clean))
            
        except Exception as e:
            logger.error("Error inserting ticker data: %s", e)
            raise


class MacroData():
    """Model for storing macroeconomic data with bulk insert and incremental loading support."""
    
    __tablename__ = 'macro_data'
    
    def create_table(self, cursor):
        """Create the table if it doesn't exist."""
        try:
            cursor.execute(f"""
                BEGIN
                    EXECUTE IMMEDIATE 'CREATE TABLE {self.__tablename__} (
                        id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                        trade_date DATE NOT NULL,
                        series_id VARCHAR2(100) NOT NULL,
                        value NUMBER(15,6),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )';
                EXCEPTION
                    WHEN OTHERS THEN
                        IF SQLCODE != -955 THEN  -- Table already exists
                            RAISE;
                        END IF;
                END;
            """)
            logger.info("MacroData table created/verified successfully")
        except Exception as e:
            logger.error("Error creating MacroData table: %s", e)
            raise
    
    def data_exists(self, cursor, series_id: Optional[str] = None) -> bool:
        """Check if data exists in the table."""
        try:
            if series_id:
                cursor.execute(f"SELECT 1 FROM {self.__tablename__} WHERE series_id = :series_id AND ROWNUM = 1", {"series_id": series_id})
                return cursor.fetchone() is not None
            else:
                cursor.execute(f"SELECT 1 FROM {self.__tablename__} WHERE ROWNUM = 1")
                return cursor.fetchone() is not None
        except Exception as e:
            logger.error("Error checking macro data existence: %s", e)
            return False

    def get_last_date(self, cursor, series_id: Optional[str] = None) -> Optional[date_type]:
        """Get the last date for which data exists."""
        try:
            if series_id:
                cursor.execute(f"SELECT MAX(trade_date) FROM {self.__tablename__} WHERE series_id = :series_id", {"series_id": series_id})
            else:
                cursor.execute(f"SELECT MAX(trade_date) FROM {self.__tablename__}")
            result = cursor.fetchone()
            return result[0] if result else None
        except Exception as e:
            logger.error("Error getting last macro date: %s", e)
            return None

    def insert_data(self, conn, df: pd.DataFrame):
        """Insert macroeconomic data using bulk operations with incremental loading."""
        if df is None or df.empty:
            logger.warning("No macro data to insert")
            return
        
        try:
            # Prepare data for insertion
            df_clean = df.copy()
            df_clean['trade_date'] = pd.to_datetime(df_clean['date']).dt.date
            
            # Add created_at timestamp
            df_clean['created_at'] = datetime.utcnow()
            df_clean['updated_at'] = datetime.utcnow()
            
            # Use SQLAlchemy engine for pandas to_sq
            
            # Bulk insert using pandas to_sql with SQLAlchemy
            current_data = list(df_clean.itertuples(index=False, name=None))
            cols = df_clean.columns.tolist()
            placeholders = ', '.join([':' + col for col in cols])
            insert_statement = f"""
            INSERT INTO ticker_data ({', '.join(cols)})
            VALUES ({placeholders})
            """
            
            from sqlalchemy import text
            with conn.begin() as transaction:
                transaction.execute(text(insert_statement), current_data)

            logger.info("Successfully inserted %d ticker records", len(df_clean))
            

            conn.commit()
            logger.info("Successfully inserted %d macro records", len(df_clean))
            
        except Exception as e:
            logger.error("Error inserting macro data: %s", e)
            raise


class TransformedTickers():
    """Model for storing processed data with technical indicators."""
    
    __tablename__ = 'transformed_tickers'
    
    def create_table(self, cursor):
        """Create the table if it doesn't exist."""
        try:
            cursor.execute(f"""
                BEGIN
                    EXECUTE IMMEDIATE 'CREATE TABLE {self.__tablename__} (
                        id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                        ticker VARCHAR2(10) NOT NULL,
                        trans_date DATE NOT NULL,
                        open_price BINARY_DOUBLE,
                        high_price BINARY_DOUBLE,
                        low_price BINARY_DOUBLE,
                        close_price BINARY_DOUBLE,
                        volume NUMBER,
                        vwap NUMBER(10,4),
                        num_transactions NUMBER,
                        rsi BINARY_DOUBLE,
                        macd BINARY_DOUBLE,
                        macd_signal BINARY_DOUBLE,
                        macd_hist BINARY_DOUBLE,
                        stoch_k BINARY_DOUBLE,
                        stoch_d BINARY_DOUBLE,
                        cci BINARY_DOUBLE,
                        roc BINARY_DOUBLE,
                        mom BINARY_DOUBLE,
                        trix BINARY_DOUBLE,
                        willr BINARY_DOUBLE,
                        sma10 BINARY_DOUBLE,
                        sma20 BINARY_DOUBLE,
                        sma50 BINARY_DOUBLE,
                        sma100 BINARY_DOUBLE,
                        sma200 BINARY_DOUBLE,
                        ema10 BINARY_DOUBLE,
                        ema20 BINARY_DOUBLE,
                        ema50 BINARY_DOUBLE,
                        ema100 BINARY_DOUBLE,
                        ema200 BINARY_DOUBLE,
                        obv BINARY_DOUBLE,
                        ad BINARY_DOUBLE,
                        mfi BINARY_DOUBLE,
                        adosc BINARY_DOUBLE,
                        cmf BINARY_DOUBLE,
                        vwap BINARY_DOUBLE,
                        vpt BINARY_DOUBLE,
                        adx BINARY_DOUBLE,
                        rvol BINARY_DOUBLE,
                        atr BINARY_DOUBLE,
                        natr BINARY_DOUBLE,
                        trange BINARY_DOUBLE,
                        bbands_upper BINARY_DOUBLE,
                        bbands_middle BINARY_DOUBLE,
                        bbands_lower BINARY_DOUBLE,
                        ulcer_index BINARY_DOUBLE,
                        donch_upper BINARY_DOUBLE,
                        donch_lower BINARY_DOUBLE,
                        midprice BINARY_DOUBLE,
                        medprice BINARY_DOUBLE,
                        typprice BINARY_DOUBLE,
                        wclprice BINARY_DOUBLE,
                        avgprice BINARY_DOUBLE,
                        return_1d BINARY_DOUBLE,
                        return_3d BINARY_DOUBLE,
                        return_7d BINARY_DOUBLE,
                        return_30d BINARY_DOUBLE,
                        return_90d BINARY_DOUBLE,
                        return_365d BINARY_DOUBLE,
                        ht_trendline BINARY_DOUBLE,
                        ht_sine BINARY_DOUBLE,
                        ht_sine_lead BINARY_DOUBLE,
                        ht_dcperiod BINARY_DOUBLE,
                        ht_dcphase BINARY_DOUBLE,
                        stddev BINARY_DOUBLE,
                        var BINARY_DOUBLE,
                        beta_vs_sp500 BINARY_DOUBLE,
                        zscore_price_normalized BINARY_DOUBLE,
                        cdl2crows BINARY_DOUBLE,
                        cdl3blackcrows BINARY_DOUBLE,
                        cdl3inside BINARY_DOUBLE,
                        cdl3linestrike BINARY_DOUBLE,
                        cdl3outside BINARY_DOUBLE,
                        cdl3starsinsouth BINARY_DOUBLE,
                        cdl3whitesoldiers BINARY_DOUBLE,
                        cdlabandonedbaby BINARY_DOUBLE,
                        cdlbelthold BINARY_DOUBLE,
                        cdlbreakaway BINARY_DOUBLE,
                        cdlclosingmarubozu BINARY_DOUBLE,
                        cdlconcealbabyswall BINARY_DOUBLE,
                        cdlcounterattack BINARY_DOUBLE,
                        cdldarkcloudcover BINARY_DOUBLE,
                        cdldoji BINARY_DOUBLE,
                        cdldojistar BINARY_DOUBLE,
                        cdlengulfing BINARY_DOUBLE,
                        cdleveningstar BINARY_DOUBLE,
                        cdlgravestonedoji BINARY_DOUBLE,
                        cdlhammer BINARY_DOUBLE,
                        cdlhangingman BINARY_DOUBLE,
                        cdlharami BINARY_DOUBLE,
                        cdlharamicross BINARY_DOUBLE,
                        cdlhighwave BINARY_DOUBLE,
                        cdlhikkake BINARY_DOUBLE,
                        cdlhikkakemod BINARY_DOUBLE,
                        cdlhomingpigeon BINARY_DOUBLE,
                        cdlidentical3crows BINARY_DOUBLE,
                        cdlinneck BINARY_DOUBLE,
                        cdlinvertedhammer BINARY_DOUBLE,
                        cdlladderbottom BINARY_DOUBLE,
                        cdllongleggeddoji BINARY_DOUBLE,
                        cdllongline BINARY_DOUBLE,
                        cdlmarubozu BINARY_DOUBLE,
                        cdlmatchinglow BINARY_DOUBLE,
                        cdlmathold BINARY_DOUBLE,
                        cdlmorningdojistar BINARY_DOUBLE,
                        cdlmorningstar BINARY_DOUBLE,
                        cdlonneck BINARY_DOUBLE,
                        cdlpiercing BINARY_DOUBLE,
                        cdlrickshawman BINARY_DOUBLE,
                        cdlrisefall3methods BINARY_DOUBLE,
                        cdlseparatinglines BINARY_DOUBLE,
                        cdlshootingstar BINARY_DOUBLE,
                        cdlshortline BINARY_DOUBLE,
                        cdlspinningtop BINARY_DOUBLE,
                        cdlstalledpattern BINARY_DOUBLE,
                        cdlsticksandwich BINARY_DOUBLE,
                        cdltakuri BINARY_DOUBLE,
                        cdltasukigap BINARY_DOUBLE,
                        cdlthrusting BINARY_DOUBLE,
                        cdltristar BINARY_DOUBLE,
                        cdlunique3river BINARY_DOUBLE,
                        cdlxsidegap3methods BINARY_DOUBLE,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )';
                EXCEPTION
                    WHEN OTHERS THEN
                        IF SQLCODE != -955 THEN  -- Table already exists
                            RAISE;
                        END IF;
                END;
            """)
            
            # Create indexes with PL/SQL blocks
            cursor.execute(f"""
            BEGIN
                EXECUTE IMMEDIATE 'CREATE INDEX idx_{self.__tablename__}_ticker ON {self.__tablename__} (ticker)';
            EXCEPTION
                WHEN OTHERS THEN
                    IF SQLCODE != -955 THEN  -- Index already exists
                        RAISE;
                    END IF;
            END;
            """)
            
            cursor.execute(f"""
            BEGIN
                EXECUTE IMMEDIATE 'CREATE INDEX idx_{self.__tablename__}_date ON {self.__tablename__} (trans_date)';
            EXCEPTION
                WHEN OTHERS THEN
                    IF SQLCODE != -955 THEN  -- Index already exists
                        RAISE;
                    END IF;
            END;
            """)
            
            cursor.execute(f"""
            BEGIN
                EXECUTE IMMEDIATE 'CREATE INDEX idx_{self.__tablename__}_ticker_date ON {self.__tablename__} (ticker, trans_date)';
            EXCEPTION
                WHEN OTHERS THEN
                    IF SQLCODE != -955 THEN  -- Index already exists
                        RAISE;
                    END IF;
            END;
            """)
            
            logger.info("TransformedTickers table created/verified successfully")
        except Exception as e:
            logger.error("Error creating TransformedTickers table: %s", e)
            raise
    
    def data_exists(self, cursor, ticker: Optional[str] = None) -> bool:
        """Check if data exists in the table."""
        try:
            if ticker:
                cursor.execute(f"SELECT 1 FROM {self.__tablename__} WHERE ticker = :ticker", {"ticker": ticker})
                # Check if any record exists
                return cursor.fetchone() is not None
            return False
        except Exception as e:
            logger.error("Error checking transformed data existence: %s", e)
            return False
    
    def get_last_date(self, cursor, ticker: Optional[str] = None) -> Optional[date_type]:
        """Get the last date for which data exists."""
        try:
            if ticker:
                cursor.execute(f"SELECT MAX(trans_date) FROM {self.__tablename__} WHERE ticker = :ticker", {"ticker": ticker})
                result = cursor.fetchone()
                return result[0] if result else None
            return None
        except Exception as e:
            logger.error("Error getting last transformed date: %s", e)
            return None
    
    def insert_data(self, conn, df: pd.DataFrame):
        """Insert transformed data using bulk operations with incremental loading."""
        if df is None or df.empty:
            logger.warning("No transformed data to insert")
            return
        
        try:
            # Prepare data for insertion
            df_clean = df.copy()
            
            # Ensure trade_date column is properly formatted
            if 'trade_date' in df_clean.columns:
                df_clean['trade_date'] = pd.to_datetime(df_clean['trade_date']).dt.date
            
            # Add created_at timestamp
            df_clean['created_at'] = datetime.utcnow()
            df_clean['updated_at'] = datetime.utcnow()
            
            current_data = list(df_clean.itertuples(index=False, name=None))
            cols = df_clean.columns.tolist()
            placeholders = ', '.join([':' + col for col in cols])
            insert_statement = f"""
            INSERT INTO ticker_data ({', '.join(cols)})
            VALUES ({placeholders})
            """
            
            from sqlalchemy import text
            with conn.begin() as transaction:
                transaction.execute(text(insert_statement), current_data)
            
            logger.info("Successfully inserted %d transformed records", len(df_clean))
            
        except Exception as e:
            logger.error("Error inserting transformed data: %s", e)
            raise


class TransformedMacroData():
    """Model for storing transformed macroeconomic data."""
    
    __tablename__ = 'transformed_macro_data'
    
    
    def create_table(self, cursor):
        """Create the table if it doesn't exist."""
        try:
            cursor.execute(f"""
            BEGIN
                EXECUTE IMMEDIATE 'CREATE TABLE {self.__tablename__} (
                    id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    trans_date DATE NOT NULL,
                    series_id VARCHAR2(100) NOT NULL,
                    value BINARY_DOUBLE,
                    normalized_value BINARY_DOUBLE,
                    moving_avg_30 BINARY_DOUBLE,
                    year_over_year_change BINARY_DOUBLE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )';
            EXCEPTION
                WHEN OTHERS THEN
                    IF SQLCODE != -955 THEN  -- Table already exists
                        RAISE;
                    END IF;
            END;
            """)
            
            # Create indexes with PL/SQL blocks
            cursor.execute(f"""
            BEGIN
                EXECUTE IMMEDIATE 'CREATE INDEX idx_{self.__tablename__}_series ON {self.__tablename__} (series_id)';
            EXCEPTION
                WHEN OTHERS THEN
                    IF SQLCODE != -955 THEN  -- Index already exists
                        RAISE;
                    END IF;
            END;
            """)
            
            cursor.execute(f"""
            BEGIN
                EXECUTE IMMEDIATE 'CREATE INDEX idx_{self.__tablename__}_date ON {self.__tablename__} (trans_date)';
            EXCEPTION
                WHEN OTHERS THEN
                    IF SQLCODE != -955 THEN  -- Index already exists
                        RAISE;
                    END IF;
            END;
            """)
            
            logger.info("TransformedMacroData table created/verified successfully")
        except Exception as e:
            logger.error("Error creating TransformedMacroData table: %s", e)
            raise
    
    def data_exists(self, cursor, series_id: Optional[str] = None) -> bool:
        """Check if data exists in the table."""
        try:
            if series_id:
                cursor.execute(f"SELECT 1 FROM {self.__tablename__} WHERE series_id = :series_id AND ROWNUM = 1", {"series_id": series_id})
                return cursor.fetchone() is not None
            return False
        except Exception as e:
            logger.error("Error checking transformed macro data existence: %s", e)
            return False

    def get_last_date(self, cursor, series_id: Optional[str] = None) -> Optional[date_type]:
        """Get the last date for which data exists."""
        try:
            if series_id:
                cursor.execute(f"SELECT MAX(trans_date) FROM {self.__tablename__} WHERE series_id = :series_id", {"series_id": series_id})
                result = cursor.fetchone()
                return result[0] if result else None
            return None
        except Exception as e:
            logger.error("Error getting last transformed macro date: %s", e)
            return None
    
    def insert_data(self, conn, df: pd.DataFrame):
        """Insert transformed macro data using bulk operations with incremental loading."""
        if df is None or df.empty:
            logger.warning("No transformed macro data to insert")
            return
        
        try:
            # Prepare data for insertion
            df_clean = df.copy()
            
            # Ensure trade_date column is properly formatted
            if 'trade_date' in df_clean.columns:
                df_clean['trade_date'] = pd.to_datetime(df_clean['trade_date']).dt.date
            
            # Add created_at timestamp
            df_clean['created_at'] = datetime.utcnow()
            df_clean['updated_at'] = datetime.utcnow()
            
            # Bulk insert using pandas to_sql with SQLAlchemy engine
            current_data = list(df_clean.itertuples(index=False, name=None))
            cols = df_clean.columns.tolist()
            placeholders = ', '.join([':' + col for col in cols])
            insert_statement = f"""
            INSERT INTO ticker_data ({', '.join(cols)})
            VALUES ({placeholders})
            """
            
            from sqlalchemy import text
            with conn.begin() as transaction:
                transaction.execute(text(insert_statement), current_data)

            logger.info("Successfully inserted %d transformed macro records", len(df_clean))
            
        except Exception as e:
            logger.error("Error inserting transformed macro data: %s", e)
            raise
